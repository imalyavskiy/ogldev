<!DOCTYPE html><html><head><meta content="IE=edge" http-equiv="X-UA-Compatible" /><meta charset="utf-8" /><meta content="width=device-width,initial-scale=1.0,minimum-scale=1.0,maximum-scale=1.0,user-scalable=no" name="viewport" /><meta content="" name="keywords" /><meta content="" name="description" /><title>Уроки по OpenGL с сайта OGLDev - Урок 13 - Пространство камеры</title><link href="http://fonts.googleapis.com/css?family=Lato:300,400" rel="stylesheet" type="text/css" /><script src="http://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script><link href="../stylesheets/site.css" rel="stylesheet" media="all" type="text/css" /><script src="../javascripts/shCore.js"></script><script src="../javascripts/shBrushCpp.js"></script><script src="../javascripts/all.js"></script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-35259428-1', 'auto');
ga('send', 'pageview');</script></head><body><div class="row header"><div class="large-12 columns"><div class="nav-bar right"><ul class="button-group"><li><a href="../index.html" class="button nav-left">Содержание</a></li><li><a href="../instr.html" class="button">Инструкции</a></li><li><a href="../cont.html" class="button nav-right">Контакты</a></li></ul></div><h1><small>Уроки по OpenGL с сайта OGLDev</small></h1><hr /></div></div><div class="row"><div class="large-12 columns"><div class="tutorial"><h2><a href="http://ogldev.atspace.co.uk/www/tutorial13/tutorial13.html">Урок 13 - Пространство камеры</a></h2>
<p>В последней серии уроков мы видели 2 вида преобразований: Первый - изменял позицию (движение), ориентацию (вращение) или размеры (масштабирование) объекта. Эти преобразования позволяли нам поместить объект в любую точку 3D пространства. Второй - проецирование перспективы, которое принимало позицию вершины в 3D пространстве и проецировало ее в 2D (т.е. на плоскость). Когда координаты переведены в 2D, то очень легко перевести координаты в пространство экрана. Эти координаты использовались для растеризации примитивов из которых и состоит объект (точки, линии или треугольники).</p>

<p>Последний элемент мозаики - это позиция камеры. Во всех предыдущих уроках мы считали, что камера расположена в начале координат. На самом же деле нам, конечно, хотелось бы свободы перемещения камеры в любую точку, и проекция вершин должна происходить на некую плоскость перед камерой. Это задаст правильную связь между камерой и объектами на экране.</p>

<p>На следующем изображении мы видим камеру, расположенную тыльной стороной к нам. Перед ней есть виртуальная экранная плоскость, и шар проецируется на нее. Если камера наклоняется, то с ней наклоняется и плоскость. Так как обзор камеры ограничен ее же углом обзора, то видимая часть (бесконечной) плоскости - это прямоугольник. Все что вне его, обрезается. Наша цель - перенести прямоугольник на экран.</p>

<p><img src="../images/t13_camera_space.png" alt="" /></p>

<p>Теоретически, возможно генерировать преобразование, которое будет брать объект из 3D пространства и проецировать его на экранную плоскость, находящуюся прямо перед произвольно расположенной камерой. Хотя, такие математические вычисления и гораздо сложнее всего, что мы видели ранее. Всё же гораздо проще, когда камера находится в начале координат и направленна в сторону увеличения значений по оси Z. Например, объект находится в (0,0,5), а камера в (0,0,1) и направленна по оси Z (т.е. прямо на объект). Если мы подвинем и камеру и объект на одно расстояние, тогда относительные расстояние и ориентация (в значении направления камеры) останутся теми же самыми, как и в старом положении. Перемещение всех объектов на сцене в одном направлении позволит нам рендерить сцену правильно, при этом будут использоваться уже изученные методы.</p>

<p>Предыдущий пример слишком прост, поскольку камера уже направлена прямо на объект. Но что произойдет, если камера направлена как-то иначе? Давайте посмотрим на следующее изображение. Для ясности здесь изображена 2D система координат, а мы смотрим на камеру сверху.</p>

<p><img src="../images/t13_camera_axes2.png" alt="" /></p>

<p>Камера была направлена в сторону возрастания оси Z, а затем повернута на 45 градусов по часовой стрелке. Как вы видите, камера определяет свою собственную систему координат, которая может совпадать с мировой (верхнее изображение) или отличаться (нижнее). Поэтому у нас 2 системы координат одновременно. Первая "<i>мировая система координат</i>", в которой располагаются объекты, и вторая - <i>"система координат камеры"</i>, со своими осями координат. Эти 2 системы называют "<i>мировое пространство</i>" и "<i>пространство камеры</i>", соответственно.</p>

<p>Зеленый шар расположен в (0,0,z) в мировых координатах. А относительно камеры он где-то в левой верхней четверти координатной системы (т.е. у него отрицательный X и положительный Z). Нам нужно вычислить его координаты относительно системы координат камеры. Тогда мы сможем позабыть об мировом пространстве и использовать только камерное. В пространстве камеры сама камера расположена в начале координат и направлена в сторону, обратную оси Z. Объекты соотносятся с камерой и могут рендерится используя уже изученные инструменты.</p>

<p>Поворот камеры на 45 градусов по часовой стрелке все равно, что и поворот объекта на 45 градусов в обратном направлении. Движение объектов всегда противоположно движению камеры. Поэтому в целом нам нужно добавить 2 новых преобразования и включить их в имеющийся конвейер. Мы будем передвигать объекты так, что бы расстояние от них до камеры было бы таким же, как если бы камера располагалась в начале координат, и мы будем поворачивать объекты в направлении, противоположном вращению камеры.</p>

<p>Движение камеры устроено очень просто. Если координаты камеры (x,y,z), то преобразование позиции (-x, -y, -z). Причина тому проста - камера расположена в мировой системе координат с использованием перемещения, основанного на векторе (x,y,z) поэтому, что бы поместить ее обратно, необходимо преобразование, обратное данному. Вот как выглядит матрица преобразования:</p>

<p><img src="../images/t13_camera_space_translation.png" alt="" /></p>

<p>Следующий шаг - это поворот камеры на некоторые значения, указанные в мировых координатах. Нам требуется найти положение вершин в новой системе координат, устанавливаемой камерой. Поэтому логичен вопрос: как перейти из одной системы координат в другую?</p>

<p>Еще раз посмотрим на изображение выше. Мы можем сказать, что мировая система задана тремя линейно независимыми единичными векторами i(1,0,0), j(0,1,0) и k(0,0,1). Линейная независимость означает, что мы не можем найти не равные нулю вектора x, y и z такие, что x<em>(1,0,0) + y(0,1,0) + z</em>(0,0,1) = (0,0,0). Если говорить более математически, то из любой пары векторов из этой тройки, можно получить плоскость, для которой 3-й вектор будет перпендикулярным (плоскость XY перпендикулярна оси Z, и т.д). Легко заметить, что система координат камеры задана векторами X<sub>Камера</sub>(1,0,-1), Y<sub>Камера</sub>(0,1,0), Z<sub>Камера</sub>(1,0,1). После нормирования векторы станут равны ||X<sub>Камера</sub>||(0.7071,0,-0.7071), ||Y<sub>Камера</sub>||(0,1,0) и ||Z<sub>Камера</sub>||(0.7071,0,0.7071).</p>

<p>Следующее изображение показывает как вектор указывается в 2 независимых системах координат:</p>

<p><img src="../images/t13_camera_axes.png" alt="" /></p>

<p>Мы знаем, как получить единичные вектора, которые обозначат оси камеры в мировом пространства и мы знаем позицию вектора в нем (x,y,z). Нас же интересует вектор  (x',y', z'). Теперь воспользуемся значением скалярного произведения, известного как "<i>скалярная проекция</i>". <i>Скалярная проекция</i> - это результат скалярного произведения между произвольным вектором A и <i><b>единичного</b></i> вектора B, и результат это величина A в направлении B. Другими словами, проекция вектора A на вектор B. В примере выше, если мы скалярно умножим вектор (x,y,z) и единичный вектор, представляющий X у камеры, то мы получим x'. Аналогично мы можем получить y' и z'. (x',y',z') это и есть координаты  (x,y,z) в пространстве камеры.</p>

<p>Давайте рассмотрим, как собрать из этих выводов единое решение для положения камеры. Решение называется "<i>UVN камера</i>" и это одна из множества систем, характеризующих камеру. Идея в том, что камера определяется следующими векторами:</p>

<ol>
  <li><b>N</b> - Вектор от камеры к ее цели. Так же известен как вектор "<i>look at</i>" в некоторой литературе о 3D. Этот вектор соответствует <b>Z</b> оси.</li>
  <li><b>V</b> - Если стоять вертикально, то этот вектор будет исходить из головы в небо. Если вы пишите симулятор полетов, и один из них перевернут, то вектор будет указывать на землю. Этот вектор соответствует оси <b>Y</b>.</li>
  <li><b>U</b> - Этот вектор выходит из камеры направо. Соответствует оси <b>X</b>.</li>
</ol>

<p>Итак, для перевода координат из мировой системы в систему камеры, определенную векторами UVN, нам необходимо найти скалярное произведение между вектором позиции с векторами UVN. Матрица лучше всего покажет как это происходит:</p>

<p><img src="../images/t13_uvn.png" alt="" /></p>

<p>В исходном коде к этому уроку вы заметите, что переменная 'gWorld' теперь называется 'gWVP'. Это изменение отражает серии преобразований, известных во многих книгах. WVP расшифровывается как вид мировой проекции (World-View-Projection).</p>

<h2 id="httpsgithubcomtriplepointfiveogldevtreemastertutorial13"><a href="https://github.com/triplepointfive/ogldev/tree/master/tutorial13">Прямиком к коду!</a></h2>

<p>В этом уроке я решил сделать не большие изменения в структуре проекта и переместил низкоуровневые взаимодействия с матрицами из класса конвейера в их собственный класс. Теперь конвейер может инициализировать матрицу несколькими способами и собирает матрицы для создания итогового преобразования.</p>

<blockquote>
  <p>t13_pipeline.h:58</p>
</blockquote>

<pre><code>struct Camera {
  Vector3f Pos;
  Vector3f Target;
  Vector3f Up;
};</code></pre>

<p>Класс конвейера имеет несколько новых параметров для хранения данных матрицы. Заметим, что у нас отсутствует вектор вправо. Он может быть подсчитан на ходу используя векторное произведение других векторов. Кроме того, появилась новая функция SetCamera для получения этих значений.</p>

<blockquote>
  <p>math3d.h:21</p>
</blockquote>

<pre><code>Vector3f Vector3f::Cross(const Vector3f&amp; v) const
{
    const float _x = y * v.z - z * v.y;
    const float _y = z * v.x - x * v.z;
    const float _z = x * v.y - y * v.x;

    return Vector3f(_x, _y, _z);
}
</code></pre>

<p>Vector3f приобрел новый метод для векторного умножения между 2 векторами. Такая операция возвращает вектор, перпендикулярный плоскости, определяемой исходными векторами. Станет гораздо легче в понимании, когда вы вспомните, что вектор имеет направление и значения, но не имеет позиции. Все вектора, у которых совпадают направления и значения - эквивалентны, не зависимо от того, из какой точки они выходят. Поэтому вы можете представить, что все вектора выходят из начала координат. Это значит, что вы можете создать треугольник, одна из вершин которого начало координат, а 2 другие на конце векторов. Треугольник принадлежит плоскости, а результат векторного произведения дает вектор, перпендикулярный этой плоскости. Прочитайте подробнее о векторном произведении на <a href="http://en.wikipedia.org/wiki/Cross_product">Википедии</a>.</p>

<blockquote>
  <p>math3d.h:30</p>
</blockquote>
<pre><code>Vector3f&amp; Vector3f::Normalize()
{
    const float Length = sqrtf(x * x + y * y + z * z);

    x /= Length;
    y /= Length;
    z /= Length;

    return *this;
}
</code></pre>

<p>Для генерации матрицы UVN мы должны сделать вектора единичной длины. Это называется 'нормировать вектор', заключается в том, что все компоненты вектора делятся на его длину. Подробнее об этом на <a href="http://mathworld.wolfram.com/NormalizedVector.html">Mathworld</a>.</p>

<blockquote>
  <p>math3d.cpp:84</p>
</blockquote>
<pre><code>void Matrix4f::InitCameraTransform(Matrix4f& m, const Vector3f& target, const Vector3f& up)
{
  Vector3f N = Vector3f::Normalized(target);
  Vector3f V = Vector3f::Normalized(up);
  Vector3f U = V.Cross(N);

  V = N.Cross(U);

  m = Matrix4f
  {
    U.x,   U.y,   U.z,  0.0f,
    V.x,   V.y,   V.z,  0.0f,
    N.x,   N.y,   N.z,  0.0f,
    0.0f,  0.0f,  0.0f,  1.0f,
  };
}
</code></pre>

<p>Эта функция генерирует преобразования камеры, которые позднее будут использованы конвейером. Векторы U,V и N высчитываются и заносятся в ряды матрицы. Так как вектор позиции будет умножаться справа (в виде столбца), то мы получим скалярное произведение между этим вектором и векторами U,V и N. Это вычислит значения 3-х скалярных проекций, которые станут XYZ значениями позиции в пространстве экрана.</p>

<p>Функция получает вектор направления и верхний вектор. Вектор вправо вычисляется как их векторное произведение. Заметим, что мы хотим нормировать векторы в любом случае, даже если они уже единичной длины. После генерации вектор вверх пересчитывается как векторное произведение между векторами направления и вектором вправо. Причина станет ясна позднее, когда мы начнем двигать камеру. Проще обновить только вектор направления, но тогда угол между направлением и вектором вверх не будет равен 90 градусам, что нарушит линейность системы координат. После подсчета вектора вправо и затем векторно умножив его на вектор направления, мы получим обратно вектор вверх, тем самым мы получаем систему координат, у которой угол между любыми 2 осями равен 90 градусов.</p>

<blockquote>
  <p>pipeline.cpp:22</p>
</blockquote>

<pre><code>const Matrix4f& Pipeline::GetTrans()
{
  Matrix4f scaleTrans;
  Matrix4f::InitScaleTransform(scaleTrans, m_scale.x, m_scale.y, m_scale.z);
  
  Matrix4f rotateTrans;
  Matrix4f::InitRotateTransform(rotateTrans, m_rotateInfo.x, m_rotateInfo.y, m_rotateInfo.z);
  
  Matrix4f translationTrans;
  Matrix4f::InitTranslationTransform(translationTrans, m_worldPos.x, m_worldPos.y, m_worldPos.z);

  Matrix4f cameraTranslationTrans;
  Matrix4f::InitTranslationTransform(cameraTranslationTrans, -m_camera.Pos.x, -m_camera.Pos.y, -m_camera.Pos.z);
  
  Matrix4f cameraRotateTrans;
  Matrix4f::InitCameraTransform(cameraRotateTrans, m_camera.Target, m_camera.Up);

  Matrix4f perspProjTrans;
  Matrix4f::InitPersProjTransform(perspProjTrans, m_persProj.fov, m_persProj.w, m_persProj.h, m_persProj.zn, m_persProj.zf);

  m_transformation = perspProjTrans * cameraRotateTrans * cameraTranslationTrans * translationTrans * rotateTrans * scaleTrans;

  return m_transformation;
}

</code></pre>

<p>Давайте обновим функцию, генерирующую итоговую матрицу преобразований объектов. Она станет немного сложнее с 2 новыми матрицами, характеризующими участие камеры. После завершения мировых преобразований (комбинация масштабирования, вращения и перемещения объекта), мы начинаем преобразования камеры 'движением' ее обратно в начало координат. Это делается смещением на обратный вектор позиции камеры. Поэтому если камера находится в точке (1,2,3), мы двигаем объекты на (-1,-2,-3). После этого мы генерируем вращение камеры, основываясь на направлении камеры и ее векторе вверх. На этом участие камеры завершено. В конце мы проецируем координаты.</p>

<blockquote>
  <p>main.cpp:76</p>
</blockquote>

<pre><code>Vector3f CameraPos(1.0f, 1.0f, -3.0f);
Vector3f CameraTarget(0.45f, 0.0f, 1.0f);
Vector3f CameraUp(0.0f, 1.0f, 0.0f);
p.SetCamera(CameraPos, CameraTarget, CameraUp);
</code></pre>

<p>Мы используем новый функционал в главном цикле рендера. Для размещения камеры мы движемся назад, вдоль отрицательного Z, затем сдвигаемся вправо и встаем прямо. Камера глядит вдоль возрастания оси Z и немного правее относительно начала координат. Вектор вверх для простоты положительный Y. Мы назначаем это в класс конвейера, а об остальном он позаботится сам.</p>

</div><div id="disqus_thread"></div><script>/* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
var disqus_shortname = 'ogltutor'; // required: replace example with your forum shortname
var num = "13";

var disqus_config = function () {
  this.page.url = "https://triplepointfive.github.io/ogltutor/tutorials/tutorial" + num + ".html";
  this.page.identifier = num;
  this.page.title = "Урок 13 - Пространство камеры";
};

/* * * DON'T EDIT BELOW THIS LINE * * */
(function() {
  var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><noscript><Please>enable JavaScript to view the</Please><a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript><a class="dsq-brlink" href="http://disqus.com"><comments>powered by</comments><span class="logo-disqus">Disqus</span></a></div></div><footer class="row"><div class="large-12 columns text-right"><hr />Шедевр, созданный с помощью <a href="https://middlemanapp.com/">Middleman</a><br /><small><a href="https://github.com/triplepointfive/ogltutor">Исходный код</a></small></div></footer></body></html>